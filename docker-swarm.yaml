version: "3.9"

# =====================================================
#                PRODUCTION-GRADE IOT STACK
# =====================================================
services:

  # --------------------- POSTGRES ---------------------
  postgres:
    image: postgres:17
    environment:
      POSTGRES_USER: sparkuser
      POSTGRES_PASSWORD: sparkpass
      POSTGRES_DB: sensordb
    volumes:
    - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sparkuser"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
      restart_policy:
        condition: on-failure
    networks:
    - backend

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    environment:
      DATA_SOURCE_NAME: "postgresql://sparkuser:sparkpass@postgres:5432/sensordb?sslmode=disable"
    networks:
    - backend
    - monitoring
    ports:
    - "9187:9187"
    depends_on:
    - postgres
    deploy:
      restart_policy:
        condition: on-failure

  # --------------------- KAFKA CLUSTER ---------------------
  # (KRaft mode, three brokers for HA)

  # --------------------- KAFKA 1 ---------------------
  kafka1:
    image: apache/kafka:3.7.0
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_JMX_PORT: 7071
      KAFKA_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=7071"
    volumes:
    - kafka1_data:/var/lib/kafka
    ports:
    - "9092:9092"
    healthcheck:
      test: ["CMD", "sh", "-c", "echo > /dev/tcp/localhost/9092"]
      interval: 10s
      timeout: 5s
      retries: 10
    deploy:
      restart_policy:
        condition: on-failure
    networks:
      backend:
        aliases:
        - kafka1

  # --------------------- KAFKA 2 ---------------------
  kafka2:
    image: apache/kafka:3.7.0
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 2
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_JMX_PORT: 7071
      KAFKA_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=7071"
    volumes:
    - kafka2_data:/var/lib/kafka
    healthcheck:
      test: ["CMD", "sh", "-c", "echo > /dev/tcp/localhost/9092"]
      interval: 10s
      timeout: 5s
      retries: 10
    deploy:
      restart_policy:
        condition: on-failure
    networks:
      backend:
        aliases:
        - kafka2

  # --------------------- KAFKA 3 ---------------------
  kafka3:
    image: apache/kafka:3.7.0
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 3
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_JMX_PORT: 7071
      KAFKA_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=7071"
    volumes:
    - kafka3_data:/var/lib/kafka
    healthcheck:
      test: ["CMD", "sh", "-c", "echo > /dev/tcp/localhost/9092"]
      interval: 10s
      timeout: 5s
      retries: 10
    deploy:
      restart_policy:
        condition: on-failure
    networks:
      backend:
        aliases:
        - kafka3

  # --------------------- KAFKA EXPORTER ---------------------
  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    command: ["--kafka.server=kafka1:9092"]
    ports:
    - "9308:9308"
    networks:
    - monitoring
    - backend
    deploy:
      restart_policy:
        condition: on-failure

  # --------------------- PRODUCER ---------------------
  producer:
    image: producer:v3
    environment:
    - KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092,kafka3:9092
    volumes:
    - ./producer:/app
    - ./logs:/app/logs
    depends_on:
    - kafka1
    networks:
    - backend
    deploy:
      restart_policy:
        condition: on-failure

  # --------------------- SPARK MASTER ---------------------
  spark:
    image: apache/spark:3.5.0
    hostname: spark
    command: >
      bash -c "
        export SPARK_HOME=/opt/spark &&
        /opt/spark/sbin/start-master.sh &&
        tail -F /opt/spark/logs/*.out
      "
    environment:
    - SPARK_USER=root
    ports:
    - "7077:7077"
    - "8080:8080"
    volumes:
    - ./spark-apps:/opt/spark-apps
    - ./ivy-cache:/tmp/.ivy2
    depends_on:
    - kafka1
    - postgres
    networks:
    - backend
    - monitoring
    deploy:
      restart_policy:
        condition: on-failure

  # --------------------- SPARK WORKERS ---------------------
  spark-worker-1:
    image: apache/spark:3.5.0
    command: >
      bash -c "
        /opt/spark/sbin/start-worker.sh spark://spark:7077 &&
        tail -F /opt/spark/logs/*.out
      "
    environment:
    - SPARK_WORKER_CORES=4
    - SPARK_WORKER_MEMORY=8G
    depends_on:
    - spark
    networks:
    - backend
    deploy:
      restart_policy:
        condition: on-failure

  spark-worker-2:
    image: apache/spark:3.5.0
    command: >
      bash -c "
        /opt/spark/sbin/start-worker.sh spark://spark:7077 &&
        tail -F /opt/spark/logs/*.out
      "
    environment:
    - SPARK_WORKER_CORES=4
    - SPARK_WORKER_MEMORY=8G
    depends_on:
    - spark
    networks:
    - backend
    deploy:
      restart_policy:
        condition: on-failure

  # --------------------- SPARK JOB ---------------------
  spark-job:
    image: apache/spark:3.5.0
    entrypoint: ["/opt/spark/bin/spark-submit"]
    command: ["--master", "spark://spark:7077", "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.7.3", "/opt/spark-apps/spark_streaming.py"]
    volumes:
    - ./spark-apps:/opt/spark-apps
    - ./checkpoints:/tmp/spark-checkpoints
    depends_on:
    - spark
    - kafka1
    - postgres
    networks:
    - backend
    deploy:
      restart_policy:
        condition: on-failure

  # --------------------- KAFKA UI ---------------------
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
    - "8081:8080"
    environment:
    - KAFKA_CLUSTERS_0_NAME=prod
    - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092,kafka2:9092,kafka3:9092
    networks:
    - backend

  # --------------------- PROMETHEUS ---------------------
  prometheus:
    image: prom/prometheus:latest
    volumes:
    - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    - prometheus-data:/prometheus
    ports:
    - "9090:9090"
    networks:
    - monitoring
    - backend
    deploy:
      restart_policy:
        condition: on-failure

  # --------------------- GRAFANA ---------------------
  grafana:
    image: grafana/grafana:latest
    environment:
    - GF_SECURITY_ADMIN_USER=admin
    - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
    - "3000:3000"
    depends_on:
    - prometheus
    volumes:
    - grafana-data:/var/lib/grafana
    networks:
    - monitoring
    deploy:
      restart_policy:
        condition: on-failure

# =====================================================
#                     VOLUMES
# =====================================================
volumes:
  postgres_data:
  kafka1_data:
  kafka2_data:
  kafka3_data:
  prometheus-data:
  grafana-data:

    # =====================================================
    #                     NETWORKS
    # =====================================================
networks:
  backend:
    external: true
    name: iot_backend
  monitoring:
    driver: overlay
    attachable: true
